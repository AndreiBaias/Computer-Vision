{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ZpoTZudv_LK5"},"source":["## Straturi Noi\n","\n","In continuare o sa utilizam o parte din straturile prezentate in curs.\n","\n","Staturi noi:\n","\n","Strat Convolutional:\n","* torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0)\n","\n","Strat de Pooling:\n","* torch.nn.MaxPool2d(kernel_size, stride=None, padding=0)\n","* torch.nn.AveragePool2d(kernel_size, stride=None, padding=0)\n","\n","Strat de Adaptive Pool, intalnit adesea si ca Global Pool:\n","* torch.nn.AdaptiveAvgPool2d(output_size)\n","* torch.nn.AdaptiveMaxPool2d(output_size)\n","\n","Strat de liniarizare:\n","\n","* torch.nn.Flatten()\n","\n"]},{"cell_type":"code","source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"metadata":{"id":"XhKpPYPqfCUI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646849279452,"user_tz":-120,"elapsed":238,"user":{"displayName":"Andrei Baias","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10728064228891437981"}},"outputId":"4571800e-9eb6-49d2-d45c-97ac47453a00"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Hgcq8lKft8I","executionInfo":{"status":"ok","timestamp":1646849280004,"user_tz":-120,"elapsed":323,"user":{"displayName":"Andrei Baias","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10728064228891437981"}},"outputId":"2fd046be-c4a0-4fa3-a7de-8b054a69a4a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Mar  9 18:07:59 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   73C    P0    74W / 149W |    833MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["from tensorflow.python.client import device_lib\n","device_lib.list_local_devices()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qY7acNE9fIt6","executionInfo":{"status":"ok","timestamp":1646849280005,"user_tz":-120,"elapsed":5,"user":{"displayName":"Andrei Baias","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10728064228891437981"}},"outputId":"ae373e38-a9c8-4034-d091-3d3baf097efd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 1243700040864463584\n"," xla_global_id: -1, name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 11320098816\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 5856530422100204803\n"," physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n"," xla_global_id: 416903419]"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"5HWqK9mqHxgB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646849280252,"user_tz":-120,"elapsed":250,"user":{"displayName":"Andrei Baias","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10728064228891437981"}},"outputId":"2fe7cfc9-a1c5-4143-fca9-ba5bfa6a2544"},"source":["import numpy as np\n","import torch.nn as nn\n","import torch\n","from multiprocessing import set_start_method\n","try:\n","    set_start_method('spawn')\n","except RuntimeError:\n","    pass\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","# dummy_input_tensor = dummy_input_tensor.to(device)\n","print(device)\n","\n","dummy_input_tensor = torch.rand((1,3,100,100))  # Input random de marime 100x100 cu 3 canale\n","\n","layer = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(3,3), stride=(2,2))\n","print(\"Conv1 result shape\",layer(dummy_input_tensor).shape)\n","\n","layer = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(13,13), stride=(2,2))\n","print(\"Conv2 result shape\",layer(dummy_input_tensor).shape)\n","\n","layer = nn.MaxPool2d(kernel_size=(3,3)) # Stride este inferat din kernel size, ca fiind egal cu kernel size ca sa nu repete elementele luate\n","print(\"Pool result shape\",layer(dummy_input_tensor).shape)\n","\n","# Utilizat pentru a reduce dimensiunea input-ului la una prestabilita, util cand marimea input-ului este variabil\n","layer = nn.AdaptiveAvgPool2d(output_size=(5,5))\n","print(\"Global Pool result shape\",layer(dummy_input_tensor).shape)\n","\n","layer = nn.Flatten()\n","print(\"Flaten result shape\",layer(dummy_input_tensor).shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n","Conv1 result shape torch.Size([1, 10, 49, 49])\n","Conv2 result shape torch.Size([1, 10, 44, 44])\n","Pool result shape torch.Size([1, 3, 33, 33])\n","Global Pool result shape torch.Size([1, 3, 5, 5])\n","Flaten result shape torch.Size([1, 30000])\n"]}]},{"cell_type":"markdown","metadata":{"id":"GOTmqyCxJ3fk"},"source":["###Cerinte\n","\n","**(1p)** Utilizati o serie de Conv2D/Pool2D pentru a ajunge la urmatoarele marimi plecand de la input 3x100x100:\n","*   [1, 10, 25, 25] # hint: folositi stride si padding\n","*   [1, 10, 32, 32]\n","*   [1, 3, 2, 2]\n","\n"]},{"cell_type":"code","metadata":{"id":"7HtEeXbeKeKu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646849280252,"user_tz":-120,"elapsed":4,"user":{"displayName":"Andrei Baias","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10728064228891437981"}},"outputId":"df3d8445-716f-4ed2-bc33-c2928deccc62"},"source":["\n","dummy_input_tensor = torch.rand((1,3,100,100))  # Input random de marime 100x100 cu 3 canale\n","\n","### Completati codul pentru cerinta aici\n","layer = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(3,3), stride=(4,4))\n","print(\"Conv1 result shape\",layer(dummy_input_tensor).shape)\n","\n","layer = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(5,5), stride=(3,3))\n","print(\"Conv2 result shape\",layer(dummy_input_tensor).shape)\n","\n","# layer = nn.MaxPool2d(kernel_size=(3,3)) # Stride este inferat din kernel size, ca fiind egal cu kernel size ca sa nu repete elementele luate\n","# print(\"Pool result shape\",layer(dummy_input_tensor).shape)\n","\n","# Utilizat pentru a reduce dimensiunea input-ului la una prestabilita, util cand marimea input-ului este variabil\n","layer = nn.AdaptiveAvgPool2d(output_size=(2,2))\n","print(\"Global Pool result shape\",layer(dummy_input_tensor).shape)\n","\n","layer4 = nn.MaxPool2d(kernel_size=(35,35)) # Stride este inferat din kernel size, ca fiind egal cu kernel size ca sa nu repete elementele luate\n","print(\"Pool result shape\",layer4(dummy_input_tensor).shape)\n","\n","\n","\n","layer5 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(3,3), stride=(1,1))\n","print(\"Conv2 result shape\",layer5(dummy_input_tensor).shape)\n","a = layer5(dummy_input_tensor)\n","layer6 = nn.MaxPool2d(kernel_size=(4,4))\n","print(\"MaxPool result shape\", layer6(a).shape)\n","\n","layer = nn.Flatten()\n","print(\"Flaten result shape\",layer(dummy_input_tensor).shape)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Conv1 result shape torch.Size([1, 10, 25, 25])\n","Conv2 result shape torch.Size([1, 10, 32, 32])\n","Global Pool result shape torch.Size([1, 3, 2, 2])\n","Pool result shape torch.Size([1, 3, 2, 2])\n","Conv2 result shape torch.Size([1, 10, 98, 98])\n","MaxPool result shape torch.Size([1, 10, 24, 24])\n","Flaten result shape torch.Size([1, 30000])\n"]}]},{"cell_type":"markdown","metadata":{"id":"yvdPtetggm61"},"source":["## Instantierea seturilor de date"]},{"cell_type":"code","metadata":{"id":"czyIhYt5gmUQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646849282045,"user_tz":-120,"elapsed":1795,"user":{"displayName":"Andrei Baias","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10728064228891437981"}},"outputId":"79275202-7835-4c33-ece1-783a1ce9483e"},"source":["import torchvision\n","\n","cifar_train = torchvision.datasets.CIFAR10(\"./data\", download=True)\n","cifar_test = torchvision.datasets.CIFAR10(\"./data\", train=False)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n"]}]},{"cell_type":"markdown","metadata":{"id":"FOA4ted_hHdB"},"source":["## Crearea Dataloader-ului\n","\n","### Cerinte\n"," * **(2p)** Implementati functia de preprocesare a datelor, __collate_fn(examples)__.\n","\n","\n","Atentie! Spre deosebire de intrarea pentru retelele fully-connected, pentru retelele convolutionale intrearea nu trebuie liniarizata, ci doar normalizata.\n","\n","#### Hint\n","\n","  * Amintiti-va folosirea functiei __normalize__ din torchvision.transforms.functional din laboratorul trecut.\n","  * Modificati functia *collate_fn* din laboratorul trecut, pentru a normaliza datele in intervalul [-1, 1]"]},{"cell_type":"code","metadata":{"id":"uGHfd229hRyR"},"source":["# import torch\n","# import numpy as np\n","# from torch.utils.data import DataLoader\n","# from torchvision.transforms.functional import to_tensor, normalize\n","# import matplotlib.pyplot as plt\n","\n","# # display(cifar_train[0][0])\n","# def collate_fn(examples):\n","#   ### Completati codul pentru cerinta aici\n","#   \"\"\"\n","#     Functia primeste un batch de exemple pe care trebuie sa le transforme in tensori\n","#       si sa le puna intr-un batch de tip torch.Tensor.\n","#   \"\"\"\n","#   processed_images = []\n","#   processed_labels = []\n","\n","  \n","\n","#   for example in examples: # example este un tuplu returnat de obiectul de tip Dataset\n","#     pil_image = example[0]\n","#     pil_image_array = np.asarray(pil_image)\n","\n","#     tensor_image = to_tensor(pil_image)  # Transforma in obiect de tip torch.Tensor imaginea din example\n","    \n","#     normalized_tensor_image = normalize(tensor_image, [0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n","#     # tensor_image = tensor_image.unsqueeze(0) # Adauga inca o dimensiune la inceputul imaginii\n","#     # vector_image = normalized_tensor_image.resize_(1, 3072)\n","#     normalized_tensor_image = normalized_tensor_image.unsqueeze(0)\n","#     processed_images.append(normalized_tensor_image)\n","\n","#     label = np.array([example[1]])# Creaza un obiect de tip np.ndarray din labelul exemplului\n","#     tensor_label = torch.Tensor(label)# Creaza un obiect de tip torch.Tensor din label\n","#     tensor_label = tensor_label.unsqueeze(0) # Adauga inca o dimensiune la incepului labelului\n","#     processed_labels.append(tensor_label)\n","\n","#   torch_images = torch.cat(processed_images,  dim=0)\n","#   torch_labels = torch.cat(processed_labels, dim=1)\n","#   # torch_images = processed_images\n","#   # torch_labels = torch_images\n","\n","#   return torch_images, torch_labels\n","#   # return examples\n","\n","# train_loader = DataLoader(cifar_train, batch_size=500, shuffle=True, num_workers=2, collate_fn=collate_fn)\n","# test_loader = DataLoader(cifar_test, batch_size=1, shuffle=False, collate_fn=collate_fn)\n","# # print(len(cifar_train[0]))\n","# # fig = plt.figure(figsize = (32, 32))\n","# for index, batch in enumerate(train_loader):\n","#     # fig.add_subplot(32,32, 1)\n","#     # plt.imshow(np.array(batch[0][0]).transpose(1, 2, 0))\n","#     # fig.add_subplot(32,32, 2)\n","#     # plt.imshow(batch[0][0][0])\n","#     print(len(batch[0]))\n","#     print(batch[0][0])\n","#     print(batch[1][0])\n","#     print(len(batch[1]))\n","#     break\n","# # plt.show()\n","\n","import torch\n","import numpy as np\n","from torch.utils.data import DataLoader\n","from torchvision.transforms.functional import to_tensor, normalize\n","\n","def collate_fn(examples):\n","  ### Completati codul pentru cerinta aici\n","  processed_images = []\n","  processed_labels = []\n","\n","  for example in examples:\n","    tensor_image = to_tensor(example[0])\n","    normalized_tensor_image = normalize(tensor_image, [0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n","    normalized_tensor_image = normalized_tensor_image.unsqueeze(0)\n","    processed_images.append(normalized_tensor_image)\n","    \n","    label = np.array(example[1])\n","    tensor_label = torch.tensor(label)\n","    tensor_label = tensor_label.unsqueeze(0)\n","    processed_labels.append(tensor_label)\n","\n","  torch_images = torch.cat(processed_images, dim=0)\n","  torch_labels = torch.cat(processed_labels, dim=0)\n","  # torch_images.to(device)\n","  # torch_labels.to(device)\n","  return torch_images, torch_labels\n","\n","batch_size=500\n","train_loader = DataLoader(cifar_train, batch_size=500, shuffle=True, num_workers=0, collate_fn=collate_fn)\n","test_loader = DataLoader(cifar_test, batch_size=1, shuffle=False, collate_fn=collate_fn)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cnV6PIC1kQMi"},"source":["## Crearea unei retele neurale convolutionale\n","\n","### Cerinte\n"," * **(1p)** Creati o clasa care mosteneste clasa nn.Module. Ea va reprezenta o retea neurala convolutionala pentru clasificare ale celor 10 clase din datasetul CIFAR10.\n","    * Reteaua trebuie sa aiba 2 straturi convolutionale care sa reduca dimensiunea spatiala a imaginii\n","    * Liniarizati iesirea celui de-al doilea strat convolutional\n","    * Adaugat stratul final de tipul 'fully-connected'\n","    * Folositi o functie de activare la alegere\n","\n","#### Hint\n","\n","Pentru a liniariza iesirea din cel de-al doilea feature map puteti adopta mai multe strategii:\n","  * Liniarizare prin schimbarea shape-ului la [batch_size, -1]\n","  * Global Max Pooling si apoi liniarizare la [batch_size, -1]\n","  * Average Max Pooling si apoi liniarizare la [batch_size, -1]"]},{"cell_type":"code","metadata":{"id":"u1Ddc7D-lAEN"},"source":["import torch.nn as nn\n","\n","class Net(nn.Module):\n","  def __init__(self):\n","    super(Net, self).__init__()\n","    self.layer1 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(3,3), stride=(2,2))\n","    self.layer2 = nn.Conv2d(in_channels=10, out_channels=5, kernel_size=(3,3), stride=(2,2))\n","    self.flatten = nn.Flatten()\n","    self.linear = nn.Linear(245,10)\n","    self.activation = nn.ReLU() \n","\n","  def forward(self,x):\n","    output_layer1 = self.layer1(x)\n","    output1 = self.activation(output_layer1)\n","    output1.to(device)\n","    output_layer2 = self.layer2(output1)\n","    output2 = self.flatten(output_layer2)\n","    output2 = self.activation(output2)\n","    output2.to(device)\n","    output_linear = self.linear(output2)\n","    output = self.activation(output_linear)\n","    output.to(device)\n","    return output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wK0Z9NeYTghv"},"source":["## Definirea obiectelor folosite in timpul antrenarii\n","\n","### Cerinte **(1p)**\n","  * Initializati numarul de epoci\n","  * Initializati retea\n","  * Initializati optimizator\n","  * Initializati functia de cost"]},{"cell_type":"code","metadata":{"id":"Az3WKQdpod34"},"source":["# import torch.optim as optim\n","\n","# # Definiti numarul de epoci\n","# epochs = 10\n","\n","# # Definiti reteaua\n","# network = Net()\n","\n","\n","# # Definiti optimizatorul\n","# optimizer = optim.SGD(network.parameters(), lr=1e-2)\n","\n","# \"\"\"\n","# Dupa definirea optimizatorului si dupa fiecare iteratie de antrenare, trebuie \n","# apelata functia zero_grad() pentru a seta valoare tuturor gradientilor la zero.\n","# \"\"\"\n","# # Completati aici codul pentru seta valoare tuturor gradientilor la zero\n","# optimizer.zero_grad()\n","\n","# # Definiti functia cost pentru clasificare Cross-Entropy\n","# loss_fn = nn.CrossEntropyLoss()\n","# # loss_fn = loss_fn(500)\n","import torch.optim as optim\n","\n","# Definiti numarul de epoci\n","epochs = 10\n","\n","# Definiti reteaua\n","network = Net()\n","\n","# Definiti optimizatorul\n","optimizer = optim.SGD(network.parameters(), lr=1e-2,momentum=0.8)\n","# Dupa definirea optimizatorului si dupa fiecare iteratie trebuie apelata functia zero_grad().\n","# Aceasta face toti gradientii zero.\n","# Completati codul pentru a face gradientii zero aici\n","optimizer.zero_grad()\n","\n","\n","# Definiti functia cost pentru clasificare Cross-Entropy\n","loss_fn = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GAnUsWYWodb4"},"source":["## Definirea functiei de antrenare"]},{"cell_type":"code","metadata":{"id":"K9MTYanoMZ8H"},"source":["# def test_acc(net: nn.Module, test_loader: DataLoader):\n","#   net.eval()\n","\n","#   total = 0\n","#   correct = 0\n","\n","#   for test_images, test_labels in test_loader:\n","#     total += len(test_images)\n","#     out_class = torch.argmax(net(test_images))\n","#     correct += torch.sum(out_class == test_labels)\n","\n","#   return correct / total * 100\n","\n","\n","# def train_fn(epochs: int, train_loader: DataLoader, test_loader: DataLoader, \n","#              net: nn.Module, loss_fn: nn.Module, optimizer: optim.Optimizer):\n","#   # Iteram prin numarul de epoci\n","#   for e in range(epochs):\n","#     net.train()\n","\n","#     # Iteram prin fiecare batch din dataloader\n","#     for images, labels in train_loader:\n","#       # Aplicam reteaua neurala pe imaginile din batch-ul curent\n","#       out = net(images)\n","#       # labels = labels.squeeze(1)\n","#       # labels = labels.unsqueeze(-1)\n","#       # labels = labels.unsqueeze(-1)\n","#       # Aplicam functia cost pe iesirea retelei neurale si pe etichetele imaginilor \n","#       loss = loss_fn(out, labels)\n","#       # Aplicam algoritmul de back-propagation\n","#       loss.backward()\n","#       # Facem pasul de optimizare, pentru a actualiza parametrii retelei\n","#       optimizer.step()\n","#       # Apelam functia zero_grad() pentru a uita gradientii de la iteratie curenta\n","#       optimizer.zero_grad()\n","    \n","#     print(\"Loss-ul la finalul epocii {} are valoarea {}\".format(e, loss.item()))\n","\n","#     # Calculam acuratetea\n","#     acc = test_acc(net, test_loader)\n","#     print(\"Acuratetea la finalul epocii {} este {:.2f}%\".format(e + 1, acc))\n","def test_acc(net: nn.Module, test_loader: DataLoader):\n","  net.eval()\n","\n","  total = 0\n","  correct = 0\n","\n","  for test_images, test_labels in test_loader:\n","    total += len(test_images)\n","    out_class = torch.argmax(net(test_images))\n","    correct += torch.sum(out_class == test_labels)\n","\n","  return correct / total * 100\n","\n","\n","def train_fn(epochs: int, train_loader: DataLoader, test_loader: DataLoader, \n","             net: nn.Module, loss_fn: nn.Module, optimizer: optim.Optimizer):\n","  \n","  use_cuda = True\n","  # Iteram prin numarul de epoci\n","  for e in range(epochs):\n","    net.to(device)\n","    net.train()\n","    # Iteram prin fiecare exemplu din dataset\n","    for images, labels in train_loader:\n","      if use_cuda:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","      # Aplicam reteaua neurala pe imaginile de intrare\n","      out = net(images)\n","      # Aplicam functia cost pe iesirea retelei neurale si pe adnotarile imaginilor \n","      loss = loss_fn(out, labels.to(device))\n","      # Aplicam algoritmul de back-propagation\n","      loss.backward()\n","      # Facem pasul de optimizare, pentru a aplica gradientii pe parametrii retelei\n","      optimizer.step()\n","      # Apelam functia zero_grad() pentru a uita gradientii de la iteratie curenta\n","      optimizer.zero_grad()\n","    \n","    print(\"Loss-ul la finalul epocii {} are valoarea {}\".format(e, loss.item()))\n","\n","    # Caluculul acuratetii\n","    count = len(test_loader)\n","    correct = 0\n","\n","    for test_image, test_label in test_loader:\n","      if use_cuda:\n","        test_label = test_label.to(device)\n","        test_image = test_image.to(device)\n","      out_class = torch.argmax(net(test_image))\n","      if out_class == test_label:\n","        correct += 1\n","\n","    print(\"Acuratetea la finalul epocii {} este {:.2f}%\".format(e, (correct / count) * 100))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OWvb00A-TkJq"},"source":["\n","## Antrenarea\n","\n","### Cerinte\n","  * Antrenati reteaua definita mai sus (clasa Net)"]},{"cell_type":"code","metadata":{"id":"ZqUwOWmDMpqQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6f23ba91-0e55-4051-8d32-afca5df988f1","executionInfo":{"status":"ok","timestamp":1646849539689,"user_tz":-120,"elapsed":257648,"user":{"displayName":"Andrei Baias","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10728064228891437981"}}},"source":["# for images, labels in train_loader:\n","#     print(images.size())\n","#     # print(images[0])\n","#     print('#########', len(images[0]))\n","#     print(labels.size())\n","#     break\n","\n","  \n","# for images, labels in train_loader:\n","#       # Aplicam reteaua neurala pe imaginile din batch-ul curent\n","#       out = network(images)\n","#       # Aplicam functia cost pe iesirea retelei neurale si pe etichetele imaginilor \n","#       # loss = loss_fn(out, labels)\n","#       # print(out)\n","#       # print(loss)\n","      \n","#       print(labels.size())\n","train_fn(epochs, train_loader, test_loader, network, loss_fn, optimizer)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loss-ul la finalul epocii 0 are valoarea 2.2713608741760254\n","Acuratetea la finalul epocii 0 este 16.75%\n","Loss-ul la finalul epocii 1 are valoarea 2.1268997192382812\n","Acuratetea la finalul epocii 1 este 25.88%\n","Loss-ul la finalul epocii 2 are valoarea 1.9940147399902344\n","Acuratetea la finalul epocii 2 este 29.70%\n","Loss-ul la finalul epocii 3 are valoarea 1.995213508605957\n","Acuratetea la finalul epocii 3 este 31.61%\n","Loss-ul la finalul epocii 4 are valoarea 1.9537250995635986\n","Acuratetea la finalul epocii 4 este 32.98%\n","Loss-ul la finalul epocii 5 are valoarea 1.8550693988800049\n","Acuratetea la finalul epocii 5 este 33.82%\n","Loss-ul la finalul epocii 6 are valoarea 1.8350456953048706\n","Acuratetea la finalul epocii 6 este 35.37%\n","Loss-ul la finalul epocii 7 are valoarea 1.855723261833191\n","Acuratetea la finalul epocii 7 este 36.42%\n","Loss-ul la finalul epocii 8 are valoarea 1.7661441564559937\n","Acuratetea la finalul epocii 8 este 37.04%\n","Loss-ul la finalul epocii 9 are valoarea 1.8184974193572998\n","Acuratetea la finalul epocii 9 este 37.70%\n"]}]},{"cell_type":"markdown","metadata":{"id":"zmVavwztTZkz"},"source":["## Reteaua LeNet\n","\n","### Cerinte\n","  * **(2.5p)** Implementati reteaua LeNet dupa figura de mai jos si antrenati-o\n","\n","\n","![alt text](https://drive.google.com/uc?id=1OVancUyIViMRMZdULFSVCvXJHQP0NGUV)\n","\n","Figura arhitectura LeNet\n","\n","![alt text](https://debuggercafe.com/wp-content/uploads/2019/07/Layers-in-LeNet.png)\n","\n","Tabel arhitectura LeNet\n"]},{"cell_type":"code","metadata":{"id":"zoe1vbggO-4U"},"source":["\n","import torch.nn as nn\n","\n","class LeNet(nn.Module):\n","  def __init__(self):\n","    super(LeNet, self).__init__()\n","    ### Completati codul pentru cerinta aici\n","    self.layer1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=(5,5), stride=(1,1))\n","    self.activation = nn.ReLU()\n","    # self.activation = nn.GELU()\n","    self.avgPool1 = nn.AvgPool2d(kernel_size = (2,2), stride=(2,2), padding=0)\n","    self.layer2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5,5), stride=(1,1))\n","    self.avgPool2 = nn.AvgPool2d(kernel_size = (2,2), stride=(2,2), padding=0)\n","    self.layer3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=(5,5), stride=(1,1))\n","    self.linear = nn.Linear(120,84)\n","    self.linear2 = nn.Linear(84,10)\n","    self.softmax = nn.Softmax(dim = 1)\n","    self.flatten = nn.Flatten()\n","    self.norm1 = nn.BatchNorm2d(6)\n","\n","  def forward(self,x):\n","    ### Completati codul pentru cerinta aici\n","    output_layer1 = self.layer1(x)\n","    output1 = self.activation(output_layer1)\n","    output_avgPool1 = self.avgPool1(output1)\n","    output2 = self.activation(output_avgPool1)\n","    #doar in train3\n","    output2 = self.norm1(output2)\n","    output_layer2 = self.layer2(output2)\n","    output3 = self.activation(output_layer2)\n","    output_avgPool1 = self.avgPool1(output3)\n","    output4 = self.activation(output_avgPool1)\n","    #doar in train2 si train3\n","    output_avgPool2 = self.avgPool2(output3)\n","\n","    output_layer3 = self.layer3(output4)\n","    output5 = self.activation(output_layer3)\n","    output5 = self.flatten(output5)\n","    output_linear = self.linear(output5)\n","    output6 = self.activation(output_linear)\n","    output_linear2 = self.linear2(output6)\n","    output7 = self.softmax(output_linear2)\n","    \n","\n","\n","    return output7"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J0XPmGrEol9M"},"source":["## Redefinirea obiectelor folosite in timpul antrenarii pentru reteaua LeNet\n","\n","### Cerinta\n"," * **(0.5p)** Redefiniti obiectele necesare pentru a antrena reteaua LeNet"]},{"cell_type":"code","metadata":{"id":"jhqNoDmQo66c"},"source":["import torch.optim as optim\n","\n","# Definiti numarul de epoci\n","epochs = 10\n","\n","# Definiti reteaua\n","# lenet = LeNet()\n","lenet = LeNet().cuda()\n","\n","# Definiti optimizatorul\n","lenet_optimizer = optim.Adam(lenet.parameters(), lr=1e-3)\n","# lenet_optimizer = optim.SGD(lenet.parameters(), lr=1e-3)\n","# Dupa definirea optimizatorului si dupa fiecare iteratie trebuie apelata functia zero_grad().\n","# Aceasta face toti gradientii zero.\n","# Completati codul pentru a face gradientii zero aici\n","optimizer.zero_grad()\n","\n","# Definiti functia cost pentru clasificare Cross-Entropy\n","loss_fn = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hwIQwUQpo_eR"},"source":["## Antrenarea retelei LeNet"]},{"cell_type":"code","metadata":{"id":"UUl8W42do_sL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646849865006,"user_tz":-120,"elapsed":325327,"user":{"displayName":"Andrei Baias","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10728064228891437981"}},"outputId":"3e3db457-2496-48e1-c29c-ea153e9d8763"},"source":["train_fn(epochs, train_loader, test_loader, lenet, loss_fn, lenet_optimizer)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loss-ul la finalul epocii 0 are valoarea 2.0758843421936035\n","Acuratetea la finalul epocii 0 este 23.03%\n","Loss-ul la finalul epocii 1 are valoarea 2.01867413520813\n","Acuratetea la finalul epocii 1 este 25.84%\n","Loss-ul la finalul epocii 2 are valoarea 2.025395154953003\n","Acuratetea la finalul epocii 2 este 27.43%\n","Loss-ul la finalul epocii 3 are valoarea 1.9797725677490234\n","Acuratetea la finalul epocii 3 este 33.89%\n","Loss-ul la finalul epocii 4 are valoarea 1.9297038316726685\n","Acuratetea la finalul epocii 4 este 31.54%\n","Loss-ul la finalul epocii 5 are valoarea 1.9302693605422974\n","Acuratetea la finalul epocii 5 este 35.80%\n","Loss-ul la finalul epocii 6 are valoarea 1.9188045263290405\n","Acuratetea la finalul epocii 6 este 36.79%\n","Loss-ul la finalul epocii 7 are valoarea 1.8957791328430176\n","Acuratetea la finalul epocii 7 este 38.60%\n","Loss-ul la finalul epocii 8 are valoarea 1.9024308919906616\n","Acuratetea la finalul epocii 8 este 39.08%\n","Loss-ul la finalul epocii 9 are valoarea 1.8908437490463257\n","Acuratetea la finalul epocii 9 este 38.76%\n"]}]},{"cell_type":"markdown","metadata":{"id":"OspDtfFnTodr"},"source":["###Augmentare retea\n","\n","Reteaua de mai devreme duce lipsa de regularizare. O forma foarte puternica de regularizare este normalizarea, iar pentru acest lucru exista straturi speciale.\n","\n","Astfel de straturi:\n","\n","* torch.nn.BatchNorm2d(num_features)\n","* torch.nn.InstanceNorm2d(num_features)\n","\n","Un alt element important il reprezinta functiile de activare, care pot influenta convergenta si puterea retelei. Cateva exemple de functii de activate:\n","\n","\n","* Relu\n","* Sigmoid\n","* Tanh\n","* LeakyRelu\n","* GELU\n","\n","## Cerinta\n","\n","**(2p)** Experimentati cu augmentarile mentionate mai sus in cadrul ultimei retele definite pentru a obtine o acuratete mai buna. Observati viteza de convergenta si performanta retelei pentru 3 configuratii diferite.\n","\n","\n","###Bonus\n","**(1p)** Antrenati reteaua folosind GPU (Graphics processing unit)\n","\n","\n","\n","\n","\n","\n","\n","\n","  \n"]}]}
